{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNslrbgLRLjhMcaq54EV5g7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futureCodersSE/python-cyber/blob/main/Cloud/Reading_from_and_saving_to_S3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting to AWS Simple Storage System (S3)\n",
        "---\n",
        "To connect to, read files from and write files to S3 you will need the following:\n",
        "\n",
        "\n",
        "\n",
        "*   Get an access key (which you should keep hidden)  \n",
        "*   install the python library `boto3`   \n",
        "*   write a function get an S3 connection\n",
        "*   read or write a file as you need to\n",
        "\n"
      ],
      "metadata": {
        "id": "OLyJadlYUQ30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use this code cell to install boto3 for use in this worksheet\n",
        "---\n",
        "Use this code to do this:\n",
        "`!pip install boto3`\n",
        "\n",
        "***Note 1***:  you will need to do this each time you come back to the worksheet.  If someone else copies your worksheet, they will need to install it.\n",
        "\n",
        "***Note 2***: once you have installed it in a session, you won't need to install it again, so put the code in a cell that you only run once."
      ],
      "metadata": {
        "id": "Msbx3QBoWEF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "id": "jHUliNAyWlej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save your access key, and secret key in an environment variable\n",
        "---\n",
        "\n",
        "During testing you will save the keys in environment variables here.  When you create a function in lambda you will use the environment variables there.\n",
        "\n",
        "1.  In the AWS console - go to the IAM service.  Follow instructions here to create your access keys: https://docs.google.com/document/d/1_FhKLVLSaBdck1e-Pm4mlUQkIj9BGwPfuquMPHpXdls/edit?usp=sharing   \n",
        "2.  Once you have downloaded the keys in a CSV so that you have a permanent record to copy and paste from (kept on your own device, or in your own cloud storage if you can't store on the device), you will be able to use them to connect to S3.\n",
        "\n",
        "3.  Create a bucket (a folder) to store your files.  Follow the instructions here: https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket.html  (there is quite a bit of information about changing setting, leave everything as the default for this exercise)  \n",
        "\n",
        "3.  Use the code cell below to allow you to input the public key (AWS_ACCESS_KEY), the private key (AWS_SECRET_ACCESS_KEY), and the bucket name,  and save all three in environment variables only available in this worksheet while you are using it.\n",
        "\n",
        "***Note 2***:  you will need to do this each time you come back to the worksheet.  If someone else copies your worksheet, they should not be able to upload to your S3 as they won't know the keys and they won't know the bucket URL (as you will also save that in an environment variable)\n",
        "\n",
        "**Environment variables**  \n",
        "When it is important not to disclose the value of certain data, you can 'decouple' it from the code by storing it in the operating system environment.   This is done, in Python, using os.environ[] to set a variable and os.environ.get() to get the value of a variable.  \n",
        "\n",
        "The data is stored alongside the operating system's data so it is not visible to anyone reading the python code.  \n",
        "\n",
        "Here, you will save the environment variables in the colab's operating system.\n",
        "On a local device, you save them in your operating system, or in a virutal environment that you create.\n",
        "On AWS Lambda, there is a space for creating environment variables, which are then used in the same way."
      ],
      "metadata": {
        "id": "EZhg5WXdW8na"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0V-74wDUUCiC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def set_environment_variable_values():\n",
        "  ACCESS_KEY = input(\"Please enter the AWS access key: \")\n",
        "  SECRET_ACCESS_KEY = input(\"Please enter the AWS secret access key: \")\n",
        "  BUCKET_NAME = input(\"Please enter the name of the bucket in S3: \")\n",
        "  os.environ['ACCESS_KEY'] = ACCESS_KEY\n",
        "  os.environ['SECRET_ACCESS_KEY'] = SECRET_ACCESS_KEY\n",
        "  os.environ['BUCKET_NAME'] = BUCKET_NAME\n",
        "  clear_output()\n",
        "  return None\n",
        "\n",
        "set_environment_variable_values()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a connection to the S3 bucket\n",
        "---\n",
        "\n",
        "In order to work with files in the bucket you will need a 'client'.  This will be the worker that will do the fetching and storing.  The code below will set up this client and the output will show that a client has been created."
      ],
      "metadata": {
        "id": "EyLPbMMlTe63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "def get_S3_client():\n",
        "\tresource = boto3.client(\n",
        "     \"s3\",\n",
        "\t\taws_access_key_id = os.environ.get('ACCESS_KEY'),\n",
        "\t\taws_secret_access_key = os.environ.get('SECRET_ACCESS_KEY')\n",
        "\t)\n",
        "\treturn resource\n",
        "\n",
        "s3_client = get_S3_client()\n",
        "print(s3_client)"
      ],
      "metadata": {
        "id": "xm0Hz9JEUwxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Opening a file from S3\n",
        "---\n",
        "\n",
        "You can upload this file to your bucket, through the AWS console.  \n",
        "\n",
        "*  Download the file (population.csv) from here:  https://drive.google.com/file/d/1Mj2f56YrgWL6eYUF9zOf0Pph8NhJAIe0/view?usp=sharing\n",
        "\n",
        "*  Open the AWS dashboard and select S3 as the service.  \n",
        "\n",
        "*  Find your bucket and click on its link to open it.  \n",
        "\n",
        "*  Click on **upload**, select the file and upload\n",
        "\n",
        "Now that the file is in the bucket, use the code below to open it."
      ],
      "metadata": {
        "id": "qfwQ9T_ZV4oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "def get_file(filename):\n",
        "  # get the file from the bucket\n",
        "  file_object = s3_client.get_object(Bucket=os.environ.get('BUCKET_NAME'), Key=filename)\n",
        "\n",
        "  # convert the file object to a text-based csv file then read the file contents into a table using the pandas read_csv function\n",
        "  data_file = file_object['Body'].read()\n",
        "  return str(data_file.decode(\"utf-8\"))\n",
        "\n",
        "data = get_file('populations.csv')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "2o-HkfsuX26E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload a new file into your bucket\n",
        "---\n",
        "\n",
        "For this exercise you are going to make a new data file (using pandas.to_csv to make the csv file, then BytesIO to convert it into a bytes object that can be stored on S3)"
      ],
      "metadata": {
        "id": "5L3F6bV9iVJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_a_copy(filedata, filename):\n",
        "  # first copy the data into a new file (print it so that you know it has been done)\n",
        "  new_data = filedata.copy()\n",
        "  print(new_data)\n",
        "\n",
        "  # make a text file object to store the data in, then convert the data csv format and place inside the file object\n",
        "  file_object =  io.StringIO()\n",
        "  new_data.to_csv(file_object, index=False)\n",
        "\n",
        "  # upload the file to the bucket with the filename and the file contents\n",
        "  response = s3_client.put_object(Bucket=os.environ.get('BUCKET_NAME'), Body=file_object.getvalue(), Key=filename)\n",
        "\n",
        "response = save_a_copy(data, 'populations_copy.csv')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "qWBJVTI-lJ8t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}